{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the shuffled data and extract vocabulary from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23007\n",
      "5752\n",
      "Total Words in Training Corpus 892224\n",
      "Vocabulary Size 37382\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv('assn_2.csv')\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# store Comment from df to corpus\n",
    "for i in range(0, len(df)):\n",
    "    corpus.append(df.iloc[i]['Comment'])\n",
    "\n",
    "# shuffle corpus\n",
    "import random\n",
    "random.seed(0)\n",
    "random.shuffle(corpus)\n",
    "\n",
    "# split corpus into train and test\n",
    "train_corpus = corpus[:int(len(corpus)*0.8)]\n",
    "test_corpus = corpus[int(len(corpus)*0.8):]\n",
    "\n",
    "print(len(train_corpus))\n",
    "print(len(test_corpus))\n",
    "\n",
    "# vocabulary\n",
    "vocab = set()\n",
    "\n",
    "\n",
    "# total no. of words in train_corpus\n",
    "total_words = 0\n",
    "for i in range(0, len(train_corpus)):\n",
    "    try:\n",
    "        words = train_corpus[i].split()\n",
    "    except:\n",
    "        train_corpus[i] = str(train_corpus[i])\n",
    "        words = train_corpus[i].split()\n",
    "    total_words += len(words)\n",
    "    # tokens.append(words)\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "for i in range(0, len(test_corpus)):\n",
    "    try:\n",
    "        words = test_corpus[i].split()\n",
    "    except:\n",
    "        test_corpus[i] = str(test_corpus[i])\n",
    "        words = test_corpus[i].split()\n",
    "    # total_words += len(words)\n",
    "    for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "print(\"Total Words in Training Corpus\", total_words)\n",
    "print(\"Vocabulary Size\", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate all n-grams and keep track of their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4 dictonaries for unigram, bigram, trigram and quadgram frequencies\n",
    "unigram_freq = {}\n",
    "bigram_freq = {}\n",
    "trigram_freq = {}\n",
    "quadgram_freq = {}\n",
    "\n",
    "for sentence in train_corpus:\n",
    "    try:\n",
    "        words = sentence.split()\n",
    "    except:\n",
    "        sentence = str(sentence)\n",
    "        words = sentence.split()\n",
    "\n",
    "    # Calculate the frequencies of unigram\n",
    "    for i in range(len(words)):\n",
    "        unigram = words[i]\n",
    "        unigram_freq[unigram] = unigram_freq.get(unigram, 0) + 1\n",
    "\n",
    "    # Calculate the frequencies of bigram\n",
    "    for i in range(len(words) - 1):\n",
    "        bigram = (words[i], words[i + 1])\n",
    "        bigram_freq[bigram] = bigram_freq.get(bigram, 0) + 1\n",
    "\n",
    "    # Calculate the frequencies of trigram\n",
    "    for i in range(len(words) - 2):\n",
    "        trigram = (words[i], words[i + 1], words[i + 2])\n",
    "        trigram_freq[trigram] = trigram_freq.get(trigram, 0) + 1\n",
    "\n",
    "    # Calculate the frequencies of quadgram\n",
    "    for i in range(len(words) - 3):\n",
    "        quadgram = (words[i], words[i + 1], words[i + 2], words[i + 3])\n",
    "        quadgram_freq[quadgram] = quadgram_freq.get(quadgram, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892224\n"
     ]
    }
   ],
   "source": [
    "# total no. of words in train_corpus\n",
    "N = total_words\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_prob = unigram_freq.copy()\n",
    "for word in unigram_prob:\n",
    "    unigram_prob[word] = unigram_prob[word] / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of a particular n-gram, sentence and Perplexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the probability of a n-gram\n",
    "def prob(num, den):\n",
    "    size = len(den)\n",
    "\n",
    "    if(size == 0):\n",
    "        try:\n",
    "            return unigram_prob[num]\n",
    "        except:\n",
    "            return 0\n",
    "    elif(size == 1):\n",
    "        try:\n",
    "            unigram = den[0]\n",
    "            bigram = (unigram, num)\n",
    "            return bigram_freq.get(bigram, 0) / unigram_freq[unigram]\n",
    "        except:\n",
    "            return 0\n",
    "    elif(size == 2):\n",
    "        try:\n",
    "            bigram = (den[0], den[1])\n",
    "            trigram = bigram + (num,)\n",
    "            return trigram_freq.get(trigram, 0) / bigram_freq[bigram]\n",
    "        except:\n",
    "            return 0\n",
    "    elif(size == 3):\n",
    "        try:\n",
    "            trigram = (den[0], den[1], den[2])\n",
    "            quadgram = trigram + (num,)\n",
    "            return quadgram_freq.get(quadgram, 0) / trigram_freq[trigram]\n",
    "        except:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds the probability of a sentence\n",
    "def prob_of_sentence(sentence, ngram, prob):\n",
    "    try:\n",
    "        words = sentence.split()\n",
    "    except:\n",
    "        sentence = str(sentence)\n",
    "        words = sentence.split()\n",
    "    if(ngram == 1):\n",
    "        probability = 0\n",
    "        for word in words:\n",
    "            # probability *= prob(word, [])\n",
    "            # probability *= pow(prob(word, []), -1/N)\n",
    "            p = prob(word, [])\n",
    "            if(p == 0):\n",
    "                return 0\n",
    "            probability += np.log(p)\n",
    "        #     print(word, \" \", probability, \" \", np.exp(probability), \" \", pow(np.exp(probability), -1/N), \" \", np.exp((-1/N)*probability))\n",
    "        # print(ngram)\n",
    "        # return probability\n",
    "        # print((-1/N)*probability, \" \", probability, \" \", np.exp((-1/N)*probability), \" \", np.exp(probability), \" \", pow(np.exp(probability), -1/N))\n",
    "        # return pow(probability, -1/len(words))\n",
    "        return np.exp((-1/len(words))*probability)\n",
    "    elif(ngram == 2):\n",
    "        probability = 0\n",
    "        if(len(words) == 0):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        unigram = words[0]\n",
    "        # probability *= prob(unigram, [])\n",
    "\n",
    "        p = prob(unigram, [])\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        for i in range(1, len(words) - 1):\n",
    "            num = words[i]\n",
    "            den = [words[i - 1]]\n",
    "            # probability *= prob(num, den)\n",
    "            p = prob(num, den)\n",
    "            if(p == 0):\n",
    "                return 0\n",
    "            probability += np.log(p)\n",
    "\n",
    "        # return probability\n",
    "        # print((-1/N)*probability, \" \", probability, \" \", np.exp((-1/N)*probability), \" \", np.exp(probability), \" \", pow(np.exp(probability), -1/N))\n",
    "        return np.exp((-1/len(words))*probability)\n",
    "    elif(ngram == 3):\n",
    "        probability = 0\n",
    "        if(len(words) == 0):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        unigram = words[0]\n",
    "        # probability *= prob(unigram, [])\n",
    "        p = prob(unigram, [])\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        if(len(words) == 1):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        num = words[1]\n",
    "        den = [words[0]]\n",
    "        # probability *= prob(num, den)\n",
    "        p = prob(num, den)\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        for i in range(2, len(words) - 2):\n",
    "            num = words[i]\n",
    "            den = [words[i - 2], words[i - 1]]\n",
    "            # probability *= prob(num, den)\n",
    "            p = prob(num, den)\n",
    "            if(p == 0):\n",
    "                return 0\n",
    "            probability += np.log(p)\n",
    "\n",
    "        # return probability\n",
    "        # print((-1/N)*probability, \" \", probability, \" \", np.exp((-1/N)*probability), \" \", np.exp(probability), \" \", pow(np.exp(probability), -1/N))\n",
    "        return np.exp((-1/len(words))*probability)\n",
    "    elif(ngram == 4):\n",
    "        probability = 0\n",
    "        if(len(words) == 0):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        unigram = words[0]\n",
    "        # probability *= prob(unigram, [])\n",
    "        p = prob(unigram, [])\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        if(len(words) == 1):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        num = words[1]\n",
    "        den = [words[0]]\n",
    "        # probability *= prob(num, den)\n",
    "        p = prob(num, den)\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        if(len(words) == 2):\n",
    "            # return probability\n",
    "            return np.exp((-1/len(words))*probability)\n",
    "        \n",
    "        num = words[2]\n",
    "        den = [words[0], words[1]]\n",
    "        # probability *= prob(num, den)\n",
    "        p = prob(num, den)\n",
    "        if(p == 0):\n",
    "            return 0\n",
    "        probability += np.log(p)\n",
    "        for i in range(3, len(words) - 3):\n",
    "            num = words[i]\n",
    "            den = [words[i - 3], words[i - 2], words[i - 1]]\n",
    "            # probability *= prob(num, den)\n",
    "            p = prob(num, den)\n",
    "            if(p == 0):\n",
    "                return 0\n",
    "            probability += np.log(p)\n",
    "\n",
    "        # return probability\n",
    "        # print((-1/N)*probability, \" \", probability, \" \", np.exp((-1/N)*probability), \" \", np.exp(probability), \" \", pow(np.exp(probability), -1/N))\n",
    "        return np.exp((-1/len(words))*probability)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perplexity(sentence, ngram, prob):\n",
    "    N = len(sentence.split())\n",
    "    probability = prob_of_sentence(sentence, ngram, prob)\n",
    "    if(probability == 0):\n",
    "        # print(sentence,\" \", ngram, \" \")\n",
    "        return \"infinity\"\n",
    "    # return pow(prob_of_sentence(sentence, ngram, prob), -1/N)\n",
    "    # return prob_of_sentence(sentence, ngram, prob)\n",
    "    return probability\n",
    "\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for unigram model is\", perplexity(sentence, 1))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for bigram model is\", perplexity(sentence, 2))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for quadgram model is\", perplexity(sentence, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Comment, Unigram Perplexity, Bigram Perplexity, Trigram Perplexity, Quadgram Perplexity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_corpus)):\n",
    "    sentence = test_corpus[i]\n",
    "    df.loc[i] = [sentence, perplexity(sentence, 1, prob), perplexity(sentence, 2, prob), perplexity(sentence, 3, prob), perplexity(sentence, 4, prob)]\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for unigram model is\", perplexity(sentence, 1))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for bigram model is\", perplexity(sentence, 2))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for quadgram model is\", perplexity(sentence, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5752"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('assn_2_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when the ratio rise to a certain level it feel...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multilateral is not the same thing as multipol...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you guys are fucking warriors keep up the figh...</td>\n",
       "      <td>385.762435</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in order to make ema datshi work well as toppi...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if they cut off a road they are sitting ducks ...</td>\n",
       "      <td>1661.164342</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was the vlogger who apparently is a well known...</td>\n",
       "      <td>1194.0477</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go ask any muslim in pakistan and some parts o...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so it is ok to kill your own teenage students ...</td>\n",
       "      <td>1174.058487</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>straight out of the handmaids tale</td>\n",
       "      <td>2301.553353</td>\n",
       "      <td>71.32296</td>\n",
       "      <td>10.154479</td>\n",
       "      <td>7.787576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taliban al qaeda and daesh we only made an agr...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Unigram Perplexity  \\\n",
       "0  when the ratio rise to a certain level it feel...           infinity   \n",
       "1  multilateral is not the same thing as multipol...           infinity   \n",
       "2  you guys are fucking warriors keep up the figh...         385.762435   \n",
       "3  in order to make ema datshi work well as toppi...           infinity   \n",
       "4  if they cut off a road they are sitting ducks ...        1661.164342   \n",
       "5  was the vlogger who apparently is a well known...          1194.0477   \n",
       "6  go ask any muslim in pakistan and some parts o...           infinity   \n",
       "7  so it is ok to kill your own teenage students ...        1174.058487   \n",
       "8                 straight out of the handmaids tale        2301.553353   \n",
       "9  taliban al qaeda and daesh we only made an agr...           infinity   \n",
       "\n",
       "  Bigram Perplexity Trigram Perplexity Quadgram Perplexity  \n",
       "0          infinity           infinity            infinity  \n",
       "1          infinity           infinity            infinity  \n",
       "2          infinity           infinity            infinity  \n",
       "3          infinity           infinity            infinity  \n",
       "4          infinity           infinity            infinity  \n",
       "5          infinity           infinity            infinity  \n",
       "6          infinity           infinity            infinity  \n",
       "7          infinity           infinity            infinity  \n",
       "8          71.32296          10.154479            7.787576  \n",
       "9          infinity           infinity            infinity  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexities for Train Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Comment, Unigram Perplexity, Bigram Perplexity, Trigram Perplexity, Quadgram Perplexity]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alright i am pretty ignorant on the whole situ...</td>\n",
       "      <td>483.490946</td>\n",
       "      <td>66.947781</td>\n",
       "      <td>15.209775</td>\n",
       "      <td>3.656156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i m talking about citizenary outcries through ...</td>\n",
       "      <td>2766.161614</td>\n",
       "      <td>60.761454</td>\n",
       "      <td>4.315467</td>\n",
       "      <td>2.238865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glad to see that you have nothing else to say ...</td>\n",
       "      <td>736.695686</td>\n",
       "      <td>46.267731</td>\n",
       "      <td>12.578495</td>\n",
       "      <td>2.816998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha something like that macdonalds</td>\n",
       "      <td>2696.816249</td>\n",
       "      <td>45.533207</td>\n",
       "      <td>15.491547</td>\n",
       "      <td>15.491547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>because the narrative is afghanistan is comple...</td>\n",
       "      <td>691.685490</td>\n",
       "      <td>76.246686</td>\n",
       "      <td>11.377546</td>\n",
       "      <td>2.771974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its not as if indian intelligence is not activ...</td>\n",
       "      <td>1497.473362</td>\n",
       "      <td>82.775779</td>\n",
       "      <td>4.975446</td>\n",
       "      <td>1.485161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from this story the salient point of it is und...</td>\n",
       "      <td>721.536428</td>\n",
       "      <td>86.907874</td>\n",
       "      <td>7.819962</td>\n",
       "      <td>1.785059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>liberalism is extremely harmful in a revolutio...</td>\n",
       "      <td>688.777981</td>\n",
       "      <td>10.688636</td>\n",
       "      <td>2.173371</td>\n",
       "      <td>1.478359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>makes total sense i guess the only thing that ...</td>\n",
       "      <td>493.362498</td>\n",
       "      <td>89.913656</td>\n",
       "      <td>11.629895</td>\n",
       "      <td>2.505870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agreed what is done is donenow they should sol...</td>\n",
       "      <td>1009.108623</td>\n",
       "      <td>82.818955</td>\n",
       "      <td>15.127924</td>\n",
       "      <td>3.474979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Unigram Perplexity  \\\n",
       "0  alright i am pretty ignorant on the whole situ...          483.490946   \n",
       "1  i m talking about citizenary outcries through ...         2766.161614   \n",
       "2  glad to see that you have nothing else to say ...          736.695686   \n",
       "3              hahaha something like that macdonalds         2696.816249   \n",
       "4  because the narrative is afghanistan is comple...          691.685490   \n",
       "5  its not as if indian intelligence is not activ...         1497.473362   \n",
       "6  from this story the salient point of it is und...          721.536428   \n",
       "7  liberalism is extremely harmful in a revolutio...          688.777981   \n",
       "8  makes total sense i guess the only thing that ...          493.362498   \n",
       "9  agreed what is done is donenow they should sol...         1009.108623   \n",
       "\n",
       "   Bigram Perplexity  Trigram Perplexity  Quadgram Perplexity  \n",
       "0          66.947781           15.209775             3.656156  \n",
       "1          60.761454            4.315467             2.238865  \n",
       "2          46.267731           12.578495             2.816998  \n",
       "3          45.533207           15.491547            15.491547  \n",
       "4          76.246686           11.377546             2.771974  \n",
       "5          82.775779            4.975446             1.485161  \n",
       "6          86.907874            7.819962             1.785059  \n",
       "7          10.688636            2.173371             1.478359  \n",
       "8          89.913656           11.629895             2.505870  \n",
       "9          82.818955           15.127924             3.474979  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perplexity for train corpus\n",
    "df_train = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "print(df_train)\n",
    "\n",
    "for(i, sentence) in enumerate(train_corpus):\n",
    "    df_train.loc[i] = [sentence, perplexity(sentence, 1, prob), perplexity(sentence, 2, prob), perplexity(sentence, 3, prob), perplexity(sentence, 4, prob)]\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity scores for train set\n",
      "Unigram Perplexity 2917.1688100970587\n",
      "Bigram Perplexity 1026.3512898111803\n",
      "Trigram Perplexity 963.1427254040312\n",
      "Quadgram Perplexity 958.1837868142972\n"
     ]
    }
   ],
   "source": [
    "# Perplexity scores for train set\n",
    "print(\"Perplexity scores for train set\")\n",
    "print(\"Unigram Perplexity\", df_train['Unigram Perplexity'].mean())\n",
    "print(\"Bigram Perplexity\", df_train['Bigram Perplexity'].mean())\n",
    "print(\"Trigram Perplexity\", df_train['Trigram Perplexity'].mean())\n",
    "print(\"Quadgram Perplexity\", df_train['Quadgram Perplexity'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6\n",
    "### Laplace Smoothing \n",
    "##### Add-1 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_with_smooth(num, den):\n",
    "    # print(\"yo\")\n",
    "    size = len(den)\n",
    "\n",
    "    if(size == 0):\n",
    "        try:\n",
    "            return (unigram_freq[num] + 1) / (N + len(vocab))\n",
    "        except:\n",
    "            # print(1/(N + len(vocab)))\n",
    "            return 1 / (N + len(vocab))\n",
    "    elif(size == 1):\n",
    "        try:\n",
    "            unigram = den[0]\n",
    "            bigram = (unigram, num)\n",
    "            return (bigram_freq.get(bigram, 0) + 1) / (unigram_freq[unigram] + len(vocab))\n",
    "        except:\n",
    "            return 1 / len(vocab)\n",
    "    elif(size == 2):\n",
    "        try:\n",
    "            bigram = (den[0], den[1])\n",
    "            trigram = bigram + (num,)\n",
    "            return (trigram_freq.get(trigram, 0) + 1) / (bigram_freq[bigram] + len(vocab))\n",
    "        except:\n",
    "            return 1 / len(vocab)\n",
    "    elif(size == 3):\n",
    "        try:\n",
    "            trigram = (den[0], den[1], den[2])\n",
    "            quadgram = trigram + (num,)\n",
    "            return (quadgram_freq.get(quadgram, 0) + 1) / (trigram_freq[trigram] + len(vocab))\n",
    "        except:\n",
    "            return 1 / len(vocab)\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Comment, Unigram Perplexity, Bigram Perplexity, Trigram Perplexity, Quadgram Perplexity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_smooth = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "print(df_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(test_corpus)):\n",
    "    sentence = test_corpus[i]\n",
    "    df_smooth.loc[i] = [sentence, perplexity(sentence, 1, prob_with_smooth), perplexity(sentence, 2, prob_with_smooth), perplexity(sentence, 3, prob_with_smooth), perplexity(sentence, 4, prob_with_smooth)]\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for unigram model is\", perplexity(sentence, 1))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for bigram model is\", perplexity(sentence, 2))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for quadgram model is\", perplexity(sentence, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smooth.to_csv('assn_2_output_smooth.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when the ratio rise to a certain level it feel...</td>\n",
       "      <td>973.810469</td>\n",
       "      <td>3459.960773</td>\n",
       "      <td>14451.380925</td>\n",
       "      <td>19453.995572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multilateral is not the same thing as multipol...</td>\n",
       "      <td>1116.954227</td>\n",
       "      <td>1418.558688</td>\n",
       "      <td>4089.458472</td>\n",
       "      <td>3757.476847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you guys are fucking warriors keep up the figh...</td>\n",
       "      <td>399.360750</td>\n",
       "      <td>754.268339</td>\n",
       "      <td>3402.746343</td>\n",
       "      <td>4662.066764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in order to make ema datshi work well as toppi...</td>\n",
       "      <td>11040.608333</td>\n",
       "      <td>12007.639201</td>\n",
       "      <td>24692.364599</td>\n",
       "      <td>27487.673154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if they cut off a road they are sitting ducks ...</td>\n",
       "      <td>1641.600345</td>\n",
       "      <td>1815.574698</td>\n",
       "      <td>3639.853842</td>\n",
       "      <td>2025.361544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was the vlogger who apparently is a well known...</td>\n",
       "      <td>1192.835757</td>\n",
       "      <td>4011.404236</td>\n",
       "      <td>16193.346835</td>\n",
       "      <td>16806.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go ask any muslim in pakistan and some parts o...</td>\n",
       "      <td>1285.852481</td>\n",
       "      <td>5914.328198</td>\n",
       "      <td>25528.824817</td>\n",
       "      <td>31214.405087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so it is ok to kill your own teenage students ...</td>\n",
       "      <td>1192.790810</td>\n",
       "      <td>2332.785345</td>\n",
       "      <td>5241.230564</td>\n",
       "      <td>3663.764804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>straight out of the handmaids tale</td>\n",
       "      <td>2244.320770</td>\n",
       "      <td>386.440384</td>\n",
       "      <td>237.723096</td>\n",
       "      <td>89.369585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taliban al qaeda and daesh we only made an agr...</td>\n",
       "      <td>1293.638480</td>\n",
       "      <td>2743.003927</td>\n",
       "      <td>9110.275227</td>\n",
       "      <td>9741.560308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Unigram Perplexity  \\\n",
       "0  when the ratio rise to a certain level it feel...          973.810469   \n",
       "1  multilateral is not the same thing as multipol...         1116.954227   \n",
       "2  you guys are fucking warriors keep up the figh...          399.360750   \n",
       "3  in order to make ema datshi work well as toppi...        11040.608333   \n",
       "4  if they cut off a road they are sitting ducks ...         1641.600345   \n",
       "5  was the vlogger who apparently is a well known...         1192.835757   \n",
       "6  go ask any muslim in pakistan and some parts o...         1285.852481   \n",
       "7  so it is ok to kill your own teenage students ...         1192.790810   \n",
       "8                 straight out of the handmaids tale         2244.320770   \n",
       "9  taliban al qaeda and daesh we only made an agr...         1293.638480   \n",
       "\n",
       "   Bigram Perplexity  Trigram Perplexity  Quadgram Perplexity  \n",
       "0        3459.960773        14451.380925         19453.995572  \n",
       "1        1418.558688         4089.458472          3757.476847  \n",
       "2         754.268339         3402.746343          4662.066764  \n",
       "3       12007.639201        24692.364599         27487.673154  \n",
       "4        1815.574698         3639.853842          2025.361544  \n",
       "5        4011.404236        16193.346835         16806.000662  \n",
       "6        5914.328198        25528.824817         31214.405087  \n",
       "7        2332.785345         5241.230564          3663.764804  \n",
       "8         386.440384          237.723096            89.369585  \n",
       "9        2743.003927         9110.275227          9741.560308  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smooth.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of all n-gram models with smoothing on validation set\n",
      "Unigram Perplexity 2465.915730640917\n",
      "Bigram Perplexity 3332.423210388105\n",
      "Trigram Perplexity 7869.116216746474\n",
      "Quadgram Perplexity 8871.255877849007\n"
     ]
    }
   ],
   "source": [
    "# perplexity scores of all n-gram models with smoothing on validation set\n",
    "print(\"Perplexity of all n-gram models with smoothing on validation set\")\n",
    "print(\"Unigram Perplexity\", df_smooth['Unigram Perplexity'].mean())\n",
    "print(\"Bigram Perplexity\", df_smooth['Bigram Perplexity'].mean())\n",
    "print(\"Trigram Perplexity\", df_smooth['Trigram Perplexity'].mean())\n",
    "print(\"Quadgram Perplexity\", df_smooth['Quadgram Perplexity'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Comment, Unigram Perplexity, Bigram Perplexity, Trigram Perplexity, Quadgram Perplexity]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alright i am pretty ignorant on the whole situ...</td>\n",
       "      <td>502.066948</td>\n",
       "      <td>1062.700309</td>\n",
       "      <td>4120.848733</td>\n",
       "      <td>4436.875678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i m talking about citizenary outcries through ...</td>\n",
       "      <td>2627.952985</td>\n",
       "      <td>4208.490363</td>\n",
       "      <td>4122.358722</td>\n",
       "      <td>2310.458562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glad to see that you have nothing else to say ...</td>\n",
       "      <td>762.519661</td>\n",
       "      <td>965.324348</td>\n",
       "      <td>3896.009332</td>\n",
       "      <td>4071.774427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hahaha something like that macdonalds</td>\n",
       "      <td>2636.069413</td>\n",
       "      <td>566.409306</td>\n",
       "      <td>394.544489</td>\n",
       "      <td>394.544489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>because the narrative is afghanistan is comple...</td>\n",
       "      <td>709.659139</td>\n",
       "      <td>1523.143779</td>\n",
       "      <td>4359.204194</td>\n",
       "      <td>4099.176167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its not as if indian intelligence is not activ...</td>\n",
       "      <td>1496.097884</td>\n",
       "      <td>3936.319165</td>\n",
       "      <td>12284.180164</td>\n",
       "      <td>14974.639275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from this story the salient point of it is und...</td>\n",
       "      <td>735.565558</td>\n",
       "      <td>2317.580627</td>\n",
       "      <td>10542.881473</td>\n",
       "      <td>14646.097095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>liberalism is extremely harmful in a revolutio...</td>\n",
       "      <td>711.506995</td>\n",
       "      <td>277.852225</td>\n",
       "      <td>345.559551</td>\n",
       "      <td>339.534338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>makes total sense i guess the only thing that ...</td>\n",
       "      <td>512.743359</td>\n",
       "      <td>1417.280229</td>\n",
       "      <td>6015.553013</td>\n",
       "      <td>6247.145968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agreed what is done is donenow they should sol...</td>\n",
       "      <td>982.166910</td>\n",
       "      <td>2004.428041</td>\n",
       "      <td>2900.906580</td>\n",
       "      <td>1184.307201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Unigram Perplexity  \\\n",
       "0  alright i am pretty ignorant on the whole situ...          502.066948   \n",
       "1  i m talking about citizenary outcries through ...         2627.952985   \n",
       "2  glad to see that you have nothing else to say ...          762.519661   \n",
       "3              hahaha something like that macdonalds         2636.069413   \n",
       "4  because the narrative is afghanistan is comple...          709.659139   \n",
       "5  its not as if indian intelligence is not activ...         1496.097884   \n",
       "6  from this story the salient point of it is und...          735.565558   \n",
       "7  liberalism is extremely harmful in a revolutio...          711.506995   \n",
       "8  makes total sense i guess the only thing that ...          512.743359   \n",
       "9  agreed what is done is donenow they should sol...          982.166910   \n",
       "\n",
       "   Bigram Perplexity  Trigram Perplexity  Quadgram Perplexity  \n",
       "0        1062.700309         4120.848733          4436.875678  \n",
       "1        4208.490363         4122.358722          2310.458562  \n",
       "2         965.324348         3896.009332          4071.774427  \n",
       "3         566.409306          394.544489           394.544489  \n",
       "4        1523.143779         4359.204194          4099.176167  \n",
       "5        3936.319165        12284.180164         14974.639275  \n",
       "6        2317.580627        10542.881473         14646.097095  \n",
       "7         277.852225          345.559551           339.534338  \n",
       "8        1417.280229         6015.553013          6247.145968  \n",
       "9        2004.428041         2900.906580          1184.307201  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perplexity for train corpus with smoothing\n",
    "df_train_smooth = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "print(df_train_smooth)\n",
    "\n",
    "for(i, sentence) in enumerate(train_corpus):\n",
    "    df_train_smooth.loc[i] = [sentence, perplexity(sentence, 1, prob_with_smooth), perplexity(sentence, 2, prob_with_smooth), perplexity(sentence, 3, prob_with_smooth), perplexity(sentence, 4, prob_with_smooth)]\n",
    "\n",
    "df_train_smooth.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity scores for train set with smoothing\n",
      "Unigram Perplexity 2218.2721842930973\n",
      "Bigram Perplexity 2303.008751103802\n",
      "Trigram Perplexity 4697.778205566052\n",
      "Quadgram Perplexity 4899.927611814923\n"
     ]
    }
   ],
   "source": [
    "# Perplexity scores for train set with smoothing\n",
    "print(\"Perplexity scores for train set with smoothing\")\n",
    "print(\"Unigram Perplexity\", df_train_smooth['Unigram Perplexity'].mean())\n",
    "print(\"Bigram Perplexity\", df_train_smooth['Bigram Perplexity'].mean())\n",
    "print(\"Trigram Perplexity\", df_train_smooth['Trigram Perplexity'].mean())\n",
    "print(\"Quadgram Perplexity\", df_train_smooth['Quadgram Perplexity'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additive Smoothing (with k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prob_with_add_k_smooth(num, den, k=2):\n",
    "    # print(\"yo\")\n",
    "    size = len(den)\n",
    "\n",
    "    if(size == 0):\n",
    "        try:\n",
    "            return (unigram_freq[num] + k) / (N + k*len(vocab))\n",
    "        except:\n",
    "            # print(1/(N + len(vocab)))\n",
    "            return k / (N + k*len(vocab))\n",
    "    elif(size == 1):\n",
    "        try:\n",
    "            unigram = den[0]\n",
    "            bigram = (unigram, num)\n",
    "            return (bigram_freq.get(bigram, 0) + k) / (unigram_freq[unigram] + k*len(vocab))\n",
    "        except:\n",
    "            return k / k*len(vocab)\n",
    "    elif(size == 2):\n",
    "        try:\n",
    "            bigram = (den[0], den[1])\n",
    "            trigram = bigram + (num,)\n",
    "            return (trigram_freq.get(trigram, 0) + k) / (bigram_freq[bigram] + k*len(vocab))\n",
    "        except:\n",
    "            return k / k*len(vocab)\n",
    "    elif(size == 3):\n",
    "        try:\n",
    "            trigram = (den[0], den[1], den[2])\n",
    "            quadgram = trigram + (num,)\n",
    "            return (quadgram_freq.get(quadgram, 0) + k) / (trigram_freq[trigram] + k*len(vocab))\n",
    "        except:\n",
    "            return 1 / len(vocab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Comment, Unigram Perplexity, Bigram Perplexity, Trigram Perplexity, Quadgram Perplexity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df_smooth_k = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "print(df_smooth_k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(len(test_corpus)):\n",
    "    sentence = test_corpus[i]\n",
    "    df_smooth_k.loc[i] = [sentence, perplexity(sentence, 1, prob_with_add_k_smooth), perplexity(sentence, 2, prob_with_add_k_smooth), perplexity(sentence, 3, prob_with_add_k_smooth), perplexity(sentence, 4, prob_with_add_k_smooth)]\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for unigram model is\", perplexity(sentence, 1))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for bigram model is\", perplexity(sentence, 2))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "    # print(\"Perplexity of sentence \\\"\", sentence, \"\\\" for quadgram model is\", perplexity(sentence, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when the ratio rise to a certain level it feel...</td>\n",
       "      <td>984.392001</td>\n",
       "      <td>2699.351944</td>\n",
       "      <td>92.766461</td>\n",
       "      <td>20068.766347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multilateral is not the same thing as multipol...</td>\n",
       "      <td>1083.766122</td>\n",
       "      <td>510.291312</td>\n",
       "      <td>25.557242</td>\n",
       "      <td>300.201620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you guys are fucking warriors keep up the figh...</td>\n",
       "      <td>412.912164</td>\n",
       "      <td>1202.342176</td>\n",
       "      <td>642.076646</td>\n",
       "      <td>4992.317169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in order to make ema datshi work well as toppi...</td>\n",
       "      <td>9633.399212</td>\n",
       "      <td>590.439428</td>\n",
       "      <td>0.062780</td>\n",
       "      <td>27980.040875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if they cut off a road they are sitting ducks ...</td>\n",
       "      <td>1651.215138</td>\n",
       "      <td>2563.275101</td>\n",
       "      <td>996.181905</td>\n",
       "      <td>2158.607181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was the vlogger who apparently is a well known...</td>\n",
       "      <td>1203.105545</td>\n",
       "      <td>5519.764940</td>\n",
       "      <td>64.223227</td>\n",
       "      <td>17306.728318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go ask any muslim in pakistan and some parts o...</td>\n",
       "      <td>1275.030600</td>\n",
       "      <td>3023.536684</td>\n",
       "      <td>40.984129</td>\n",
       "      <td>31615.445602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so it is ok to kill your own teenage students ...</td>\n",
       "      <td>1214.514734</td>\n",
       "      <td>3170.241560</td>\n",
       "      <td>40.063989</td>\n",
       "      <td>4076.836043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>straight out of the handmaids tale</td>\n",
       "      <td>2211.727932</td>\n",
       "      <td>516.794031</td>\n",
       "      <td>319.407514</td>\n",
       "      <td>107.266558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taliban al qaeda and daesh we only made an agr...</td>\n",
       "      <td>1301.108456</td>\n",
       "      <td>1989.048741</td>\n",
       "      <td>2517.622047</td>\n",
       "      <td>10137.019941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Unigram Perplexity  \\\n",
       "0  when the ratio rise to a certain level it feel...          984.392001   \n",
       "1  multilateral is not the same thing as multipol...         1083.766122   \n",
       "2  you guys are fucking warriors keep up the figh...          412.912164   \n",
       "3  in order to make ema datshi work well as toppi...         9633.399212   \n",
       "4  if they cut off a road they are sitting ducks ...         1651.215138   \n",
       "5  was the vlogger who apparently is a well known...         1203.105545   \n",
       "6  go ask any muslim in pakistan and some parts o...         1275.030600   \n",
       "7  so it is ok to kill your own teenage students ...         1214.514734   \n",
       "8                 straight out of the handmaids tale         2211.727932   \n",
       "9  taliban al qaeda and daesh we only made an agr...         1301.108456   \n",
       "\n",
       "   Bigram Perplexity  Trigram Perplexity  Quadgram Perplexity  \n",
       "0        2699.351944           92.766461         20068.766347  \n",
       "1         510.291312           25.557242           300.201620  \n",
       "2        1202.342176          642.076646          4992.317169  \n",
       "3         590.439428            0.062780         27980.040875  \n",
       "4        2563.275101          996.181905          2158.607181  \n",
       "5        5519.764940           64.223227         17306.728318  \n",
       "6        3023.536684           40.984129         31615.445602  \n",
       "7        3170.241560           40.063989          4076.836043  \n",
       "8         516.794031          319.407514           107.266558  \n",
       "9        1989.048741         2517.622047         10137.019941  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smooth_k.to_csv('assn_2_output_smooth_add_k.csv', index=False)\n",
    "df_smooth_k.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of all n-gram models with smoothing\n",
      "Unigram Perplexity 1931.4867382755365\n",
      "Bigram Perplexity 2855.1852090505467\n",
      "Trigram Perplexity 970.2857770814861\n",
      "Quadgram Perplexity 8168.5655728357315\n"
     ]
    }
   ],
   "source": [
    "# perplexity scores of all n-gram models with smoothing\n",
    "print(\"Perplexity of all n-gram models with smoothing\")\n",
    "print(\"Unigram Perplexity\", df_smooth_k['Unigram Perplexity'].mean())\n",
    "print(\"Bigram Perplexity\", df_smooth_k['Bigram Perplexity'].mean())\n",
    "print(\"Trigram Perplexity\", df_smooth_k['Trigram Perplexity'].mean())\n",
    "print(\"Quadgram Perplexity\", df_smooth_k['Quadgram Perplexity'].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Good turing technique\n",
    "def prob_with_good_turing(num, den):\n",
    "    size = len(den)\n",
    "    d = 0.75\n",
    "    if(size == 0):\n",
    "        try:\n",
    "            return unigram_prob[num]\n",
    "        except:\n",
    "            return 0\n",
    "    elif(size == 1):\n",
    "        try:\n",
    "            unigram = den[0]\n",
    "            bigram = (unigram, num)\n",
    "\n",
    "            if bigram_freq.get(bigram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif bigram_freq.get(bigram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = bigram_freq.get(bigram, 0)-d\n",
    "\n",
    "            return frq / unigram_freq[unigram]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    elif(size == 2):\n",
    "        try:\n",
    "            bigram = (den[0], den[1])\n",
    "            trigram = bigram + (num,)\n",
    "\n",
    "            if trigram_freq.get(trigram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif trigram_freq.get(trigram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = trigram_freq.get(trigram, 0)-d\n",
    "\n",
    "            return frq / trigram_freq[trigram]\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    elif(size == 3):\n",
    "        try:\n",
    "            trigram = (den[0], den[1], den[2])\n",
    "            quadgram = trigram + (num,)\n",
    "\n",
    "            if quadgram_freq.get(quadgram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif quadgram_freq.get(quadgram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = quadgram_freq.get(quadgram, 0)-d\n",
    "            return frq/ quadgram_freq[quadgram]\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perplexity(sentence, ngram, prob):\n",
    "    try:\n",
    "        N = len(sentence.split())\n",
    "    except:\n",
    "        sentence = str(sentence)\n",
    "        N = len(sentence.split())\n",
    "    probability = prob_of_sentence(sentence, ngram, prob)\n",
    "    if(probability == 0):\n",
    "        # print(sentence,\" \", ngram, \" \")\n",
    "        return \"infinity\"\n",
    "    return pow(prob_of_sentence(sentence, ngram, prob), -1/N)\n",
    "\n",
    "print(\"Perplexity of sentence \\\"I like coffee\\\" for unigram model is\", perplexity(sentence, 1, prob_with_good_turing))\n",
    "print(\"Perplexity of sentence \\\"I like coffee\\\" for bigram model is\", perplexity(sentence, 2, prob_with_good_turing ))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for quadgram model is\", perplexity(sentence, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when the ratio rise to a certain level it feel...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multilateral is not the same thing as multipol...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you guys are fucking warriors keep up the figh...</td>\n",
       "      <td>0.762851</td>\n",
       "      <td>0.791485</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in order to make ema datshi work well as toppi...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if they cut off a road they are sitting ducks ...</td>\n",
       "      <td>0.609966</td>\n",
       "      <td>0.682512</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was the vlogger who apparently is a well known...</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.875496</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go ask any muslim in pakistan and some parts o...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so it is ok to kill your own teenage students ...</td>\n",
       "      <td>0.714207</td>\n",
       "      <td>0.708393</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>straight out of the handmaids tale</td>\n",
       "      <td>0.275209</td>\n",
       "      <td>0.478362</td>\n",
       "      <td>0.711415</td>\n",
       "      <td>0.711555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taliban al qaeda and daesh we only made an agr...</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "      <td>infinity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Unigram Perplexity  \\\n",
       "0  when the ratio rise to a certain level it feel...           infinity   \n",
       "1  multilateral is not the same thing as multipol...           infinity   \n",
       "2  you guys are fucking warriors keep up the figh...           0.762851   \n",
       "3  in order to make ema datshi work well as toppi...           infinity   \n",
       "4  if they cut off a road they are sitting ducks ...           0.609966   \n",
       "5  was the vlogger who apparently is a well known...           0.881157   \n",
       "6  go ask any muslim in pakistan and some parts o...           infinity   \n",
       "7  so it is ok to kill your own teenage students ...           0.714207   \n",
       "8                 straight out of the handmaids tale           0.275209   \n",
       "9  taliban al qaeda and daesh we only made an agr...           infinity   \n",
       "\n",
       "  Bigram Perplexity Trigram Perplexity Quadgram Perplexity  \n",
       "0          infinity           infinity            infinity  \n",
       "1          infinity           infinity            infinity  \n",
       "2          0.791485           infinity            infinity  \n",
       "3          infinity           infinity            infinity  \n",
       "4          0.682512           infinity            infinity  \n",
       "5          0.875496           infinity            infinity  \n",
       "6          infinity           infinity            infinity  \n",
       "7          0.708393           infinity            infinity  \n",
       "8          0.478362           0.711415            0.711555  \n",
       "9          infinity           infinity            infinity  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "for i in range(len(test_corpus)):\n",
    "    sentence = test_corpus[i]\n",
    "    df.loc[i] = [sentence, perplexity(sentence, 1, prob_with_good_turing), perplexity(sentence, 2, prob_with_good_turing), perplexity(sentence, 3, prob_with_good_turing), perplexity(sentence, 4, prob_with_good_turing)]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined good turing and interpolation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prob_with_good_turing_with_Interpolation(num, den):\n",
    "    size = len(den)\n",
    "    d = 0.75\n",
    "    lamda = 0.2\n",
    "    deflt = 0.001\n",
    "    if(size == 0):\n",
    "        try:\n",
    "            return unigram_prob[num]\n",
    "        except:\n",
    "            return deflt\n",
    "    elif(size == 1):\n",
    "        try:\n",
    "            unigram = den[0]\n",
    "            bigram = (unigram, num)\n",
    "\n",
    "            if bigram_freq.get(bigram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif bigram_freq.get(bigram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = bigram_freq.get(bigram, 0)-d\n",
    "\n",
    "            return ((frq / unigram_freq[unigram])+(unigram_prob[num]*lamda))\n",
    "        except:\n",
    "            return deflt\n",
    "\n",
    "    elif(size == 2):\n",
    "        try:\n",
    "            bigram = (den[0], den[1])\n",
    "            trigram = bigram + (num,)\n",
    "\n",
    "            if trigram_freq.get(trigram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif trigram_freq.get(trigram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = trigram_freq.get(trigram, 0)-d\n",
    "\n",
    "            return (frq / trigram_freq[trigram])+(unigram_prob[num]*lamda)\n",
    "        except:\n",
    "            return deflt\n",
    "\n",
    "\n",
    "    elif(size == 3):\n",
    "        try:\n",
    "            trigram = (den[0], den[1], den[2])\n",
    "            quadgram = trigram + (num,)\n",
    "\n",
    "            if quadgram_freq.get(quadgram, 0)==0:\n",
    "                frq = 0.0000270\n",
    "            elif quadgram_freq.get(quadgram, 0)==1:\n",
    "                frq = 0.446\n",
    "            else:\n",
    "                frq = quadgram_freq.get(quadgram, 0)-d\n",
    "            return (frq/ quadgram_freq[quadgram])+(unigram_prob[num]*lamda)\n",
    "        except:\n",
    "            return deflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perplexity(sentence, ngram, prob):\n",
    "    try:\n",
    "        N = len(sentence.split())\n",
    "    except:\n",
    "        sentence = str(sentence)\n",
    "        N = len(sentence.split())\n",
    "    probability = prob_of_sentence(sentence, ngram, prob)\n",
    "    if(probability == 0):\n",
    "        # print(sentence,\" \", ngram, \" \")\n",
    "        return \"infinity\"\n",
    "    return pow(prob_of_sentence(sentence, ngram, prob), -1/N)\n",
    "\n",
    "print(\"Perplexity of sentence \\\"I like coffee\\\" for unigram model is\", perplexity(sentence, 1, prob_with_good_turing))\n",
    "print(\"Perplexity of sentence \\\"I like coffee\\\" for bigram model is\", perplexity(sentence, 2, prob_with_good_turing ))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for trigram model is\", perplexity(sentence, 3))\n",
    "# print(\"Perplexity of sentence \\\"I like coffee\\\" for quadgram model is\", perplexity(sentence, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Comment', 'Unigram Perplexity', 'Bigram Perplexity', 'Trigram Perplexity', 'Quadgram Perplexity'])\n",
    "for i in range(len(test_corpus)):\n",
    "    sentence = test_corpus[i]\n",
    "    df.loc[i] = [sentence, perplexity(sentence, 1, prob_with_good_turing_with_Interpolation), perplexity(sentence, 2, prob_with_good_turing_with_Interpolation), perplexity(sentence, 3, prob_with_good_turing_with_Interpolation), perplexity(sentence, 4, prob_with_good_turing_with_Interpolation)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Unigram Perplexity</th>\n",
       "      <th>Bigram Perplexity</th>\n",
       "      <th>Trigram Perplexity</th>\n",
       "      <th>Quadgram Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when the ratio rise to a certain level it feel...</td>\n",
       "      <td>0.908092</td>\n",
       "      <td>0.922216</td>\n",
       "      <td>0.931414</td>\n",
       "      <td>0.914579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multilateral is not the same thing as multipol...</td>\n",
       "      <td>0.662591</td>\n",
       "      <td>0.743039</td>\n",
       "      <td>0.839290</td>\n",
       "      <td>0.799838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you guys are fucking warriors keep up the figh...</td>\n",
       "      <td>0.762851</td>\n",
       "      <td>0.808397</td>\n",
       "      <td>0.859822</td>\n",
       "      <td>0.791059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in order to make ema datshi work well as toppi...</td>\n",
       "      <td>0.951229</td>\n",
       "      <td>0.956670</td>\n",
       "      <td>0.963817</td>\n",
       "      <td>0.961258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if they cut off a road they are sitting ducks ...</td>\n",
       "      <td>0.609966</td>\n",
       "      <td>0.718023</td>\n",
       "      <td>0.750315</td>\n",
       "      <td>0.731743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was the vlogger who apparently is a well known...</td>\n",
       "      <td>0.881157</td>\n",
       "      <td>0.898429</td>\n",
       "      <td>0.916890</td>\n",
       "      <td>0.896774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>go ask any muslim in pakistan and some parts o...</td>\n",
       "      <td>0.971512</td>\n",
       "      <td>0.974634</td>\n",
       "      <td>0.976347</td>\n",
       "      <td>0.972481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>so it is ok to kill your own teenage students ...</td>\n",
       "      <td>0.714207</td>\n",
       "      <td>0.754869</td>\n",
       "      <td>0.798805</td>\n",
       "      <td>0.798293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>straight out of the handmaids tale</td>\n",
       "      <td>0.275209</td>\n",
       "      <td>0.480129</td>\n",
       "      <td>0.711825</td>\n",
       "      <td>0.711779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>taliban al qaeda and daesh we only made an agr...</td>\n",
       "      <td>0.788248</td>\n",
       "      <td>0.851993</td>\n",
       "      <td>0.870656</td>\n",
       "      <td>0.824880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the flag looks fake if you look closely otherw...</td>\n",
       "      <td>0.602322</td>\n",
       "      <td>0.652370</td>\n",
       "      <td>0.712763</td>\n",
       "      <td>0.691015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>holding the valley would be an achievement by ...</td>\n",
       "      <td>0.569948</td>\n",
       "      <td>0.647076</td>\n",
       "      <td>0.662332</td>\n",
       "      <td>0.662851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rape murder and drugs are haram taliban do all...</td>\n",
       "      <td>0.765711</td>\n",
       "      <td>0.797706</td>\n",
       "      <td>0.834708</td>\n",
       "      <td>0.795096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>can you dm me the accounts that are spamming s...</td>\n",
       "      <td>0.682825</td>\n",
       "      <td>0.739067</td>\n",
       "      <td>0.795341</td>\n",
       "      <td>0.761644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>that is not true check this httpsyoutubewbmqfu...</td>\n",
       "      <td>0.441630</td>\n",
       "      <td>0.570936</td>\n",
       "      <td>0.766900</td>\n",
       "      <td>0.882035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id delete this do not give the trolls ideas</td>\n",
       "      <td>0.461071</td>\n",
       "      <td>0.570004</td>\n",
       "      <td>0.645884</td>\n",
       "      <td>0.551112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>at a minimum they would be put in a tiger chai...</td>\n",
       "      <td>0.713528</td>\n",
       "      <td>0.770573</td>\n",
       "      <td>0.785874</td>\n",
       "      <td>0.762508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>do you believe that if pakistan and india ever...</td>\n",
       "      <td>0.819434</td>\n",
       "      <td>0.833913</td>\n",
       "      <td>0.859899</td>\n",
       "      <td>0.837996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>they used to shadow hide comments containing t...</td>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.808432</td>\n",
       "      <td>0.834469</td>\n",
       "      <td>0.821897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i doubt anyone here is an afghan everyone is t...</td>\n",
       "      <td>0.579890</td>\n",
       "      <td>0.677770</td>\n",
       "      <td>0.734418</td>\n",
       "      <td>0.701839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  Unigram Perplexity  \\\n",
       "0   when the ratio rise to a certain level it feel...            0.908092   \n",
       "1   multilateral is not the same thing as multipol...            0.662591   \n",
       "2   you guys are fucking warriors keep up the figh...            0.762851   \n",
       "3   in order to make ema datshi work well as toppi...            0.951229   \n",
       "4   if they cut off a road they are sitting ducks ...            0.609966   \n",
       "5   was the vlogger who apparently is a well known...            0.881157   \n",
       "6   go ask any muslim in pakistan and some parts o...            0.971512   \n",
       "7   so it is ok to kill your own teenage students ...            0.714207   \n",
       "8                  straight out of the handmaids tale            0.275209   \n",
       "9   taliban al qaeda and daesh we only made an agr...            0.788248   \n",
       "10  the flag looks fake if you look closely otherw...            0.602322   \n",
       "11  holding the valley would be an achievement by ...            0.569948   \n",
       "12  rape murder and drugs are haram taliban do all...            0.765711   \n",
       "13  can you dm me the accounts that are spamming s...            0.682825   \n",
       "14  that is not true check this httpsyoutubewbmqfu...            0.441630   \n",
       "15        id delete this do not give the trolls ideas            0.461071   \n",
       "16  at a minimum they would be put in a tiger chai...            0.713528   \n",
       "17  do you believe that if pakistan and india ever...            0.819434   \n",
       "18  they used to shadow hide comments containing t...            0.792997   \n",
       "19  i doubt anyone here is an afghan everyone is t...            0.579890   \n",
       "\n",
       "    Bigram Perplexity  Trigram Perplexity  Quadgram Perplexity  \n",
       "0            0.922216            0.931414             0.914579  \n",
       "1            0.743039            0.839290             0.799838  \n",
       "2            0.808397            0.859822             0.791059  \n",
       "3            0.956670            0.963817             0.961258  \n",
       "4            0.718023            0.750315             0.731743  \n",
       "5            0.898429            0.916890             0.896774  \n",
       "6            0.974634            0.976347             0.972481  \n",
       "7            0.754869            0.798805             0.798293  \n",
       "8            0.480129            0.711825             0.711779  \n",
       "9            0.851993            0.870656             0.824880  \n",
       "10           0.652370            0.712763             0.691015  \n",
       "11           0.647076            0.662332             0.662851  \n",
       "12           0.797706            0.834708             0.795096  \n",
       "13           0.739067            0.795341             0.761644  \n",
       "14           0.570936            0.766900             0.882035  \n",
       "15           0.570004            0.645884             0.551112  \n",
       "16           0.770573            0.785874             0.762508  \n",
       "17           0.833913            0.859899             0.837996  \n",
       "18           0.808432            0.834469             0.821897  \n",
       "19           0.677770            0.734418             0.701839  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject-VWWD5C7f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
